version: '3.9'
services:
  redis:
    # Container name is used to access locally
    container_name: redis_container
    image: redis:alpine
    # If there's an issue, we're restarting the container i.e if it fails, we
    # are going to restart
    restart: always
    ports:
      # Redis port is: 6379 inside the container and we're mapping it to 6379
      # outside the container i.e second is the port we're going to use to
      # access the service outside the container
      - '6379'
    command: redis-server --loglevel warning
    # Since we're running this locally, we need a way for a docker to store
    # the data because Redis is like a database. So the data needs to be stored
    # somewhere. And we can do that by creating volumes i.e Volumes are like
    # storage where Docker stores data. Since Redis is a DB and we are running
    # locally, data can be stored using volumes. Here we're creating local
    # volume, so the volume will be stored in the same directory. So volume
    # will contain all the information that we're sending to Redis.
    volumes:
      # volumes takes path so inside this dir, there's going to be a folder
      # called Docker volumes and then inside, there's going to be cached data
      # and we're going to map it to /data
      # This docker volume will be created when we run this service. We don't
      # need to create it. And then also its going to create this cache dir.
      # Now what this means is:
      # This is local -> `./docker-volumes/cache`
      # And this is what we're getting from Redis -> `:data`
      # So the path /data from Redis, we want to map it to Docker volumes /cache
      # on our local machine. So where the data is supposed to be stored on
      # Redis, we are mapping it to this local path on our local machine.
      - ./docker-volumes/cache:/data
  # Service name can be whatever we want
  mongodb:
    container_name: mongodb_container
    # Version latest is fine for local development
    image: mongo:latest
    restart: always
    # INITDB ROOT USERNAME and PASSWORD is optional for local development
    # We can run MongoDB without that because not required while developing
    # locally. But if we want to take it to the cloud, like maybe we want to
    # use managed service i.e we want to manage the service ourself on
    # Kubernetes, then we definitely have to configure our DB. Local development
    # works fine without environment variables.
    ports:
      # MongoDB port number is 27017. So port number within the container and
      # port number we're mapping outside the container.
      - 27017:27017
    # We need to map the volume where we want the data to be stored on our
    # local machine.
    # From documentation for mongo docker image, MongoDB volumes are usually
    # mapped to `/data/db`
    # So we're going to map out own local volume to the mongodb data path
    volumes:
      # We're using the same path i.e `./docker-volumes` so we just want one
      # folder
      # This is what will be created on our local machine -> `./docker-volumes/data`
      # And this is what we're mapping that data to -> `/data/db`
      # That's 1 to 1 mapping. i.e whatever is contained in `/data/db`, we want
      # to add it to this path `./docker-volumes/data`
      # `/data` could be anything but I chose to use standard naming convention
      - ./docker-volumes/data:/data/db
  mysql:
    container_name: mysql_container
    # If tag is not used, it'll use :latest image tag by default
    image: mysql
    # Local development
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    # If we want to access MySQL from our application, then we use all of this
    # credentials
    environment:
      - MYSQL_USER=colson
      - MYSQL_DATABASE=tradenexus_auth
      # Use strong password for production
      - MYSQL_ROOT_PASSWORD=stillhome
      - MYSQL_PASSWORD=stillhome
    ports:
      - '3306:3306'
    volumes:
      - ./docker-volumes/mysql:/var/lib/mysql
  postgres:
    container_name: postgres_container
    image: postgres
    # For postgres, we don't need any command
    restart: always
    environment:
      - POSTGRES_USER=colson
      - POSTGRES_PASSWORD=stillhome
      - POSTGRES_DATABASE=tradenexus_reviews
    ports:
      - '5432:5432'
    volumes:
      - ./docker-volumes/postgres:/var/lib/postgresql
  # For RabbitMQ, we're going to use the management-alpine version so we can
  # have access to management dashboard i.e we can see the UI for RabbitMQ.
  # For RabbitMQ itself, I'm not going to be storing any data. So I'm not
  # creating any volumes. It's possible with RabbitMQ if we really wanna make
  # our queue very durable. So that, in case there is a crash or there's a
  # restart, we can always get our data.
  # Here I won't be storing data. It will pass the data or the events that
  # I'm sending, will just pass through the queue.
  # Also, we need a default user and default password so that we can use it to
  # connect to RabbitMQ from our application and also use it to access the
  # management dashboard.
  rabbitmq:
    container_name: rabbitmq_container
    # image: rabbitmq:3.13-rc-management-alpine
    image: rabbitmq:4.1-rc-management-alpine
    restart: always
    environment:
      - RABBITMQ_DEFAULT_USER=colson
      - RABBITMQ_DEFAULT_PASS=stillhome
    # I'm going to set two different ports: AMQP protocol port and management
    # port. The protocol port will be the port we use to access from our
    # application and then the management port will be the port we use to
    # access our dashboard.
    ports:
      # AMQP protocol port
      - '5672:5672'
      # Management UI port
      - '15672:15672'
  # For Elasticsearch version ^8.11.0 and above, we need to enable security
  # on Elasticsearch and create a Kibana token for Kibana to properly connect
  # to Elasticsearch.
  # Otherwise it might not work proprety and we might experience the issue
  # where Kibana does not connect and on the browser we see the message
  # 'Kibana server is not ready yet' after waiting a long time.
  # For Elasticsearch, we're only creating a single node cluster for development
  # If using Docker Desktop -> Increase the CPU Limit to maximum and Memory
  # Limit to atleast 4 GB or better 12 GB
  # Also make sure the Elasticsearch version is at least 8. Don't use v7.x.x
  # Lot of things has changed. On v7, we could have been able to set up
  # Elasticsearch without midning security. Only when we want to go on production,
  # we had to setup security but that has changed on v8. On v8, even on
  # local development the way to setup is, security is enabled by default. So
  # if we run it without having HTTPs, without security, without a valid SSL
  # certificate, we'll get errors. So what we're going to do is, we'll disable
  # security for our local devleopment.
  # But once in the cloud, use the cloud version which is secured.
  # So, a single node cluster, at least version 8, and disable security for
  # local development!
  elasticsearch:
    container_name: elasticsearch_container
    # image: docker.elastic.co/elasticsearch/elasticsearch:8.10.4
    # image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.2
    restart: always
    # Elasticsearch in itself uses Java JVM. And there are some environment
    # variables that we need to set up. We don't need security enabled. So we
    # have to disable security in the configuration because security requires
    # us to have a valid SSL certificate that the Elasticsearch endpoint needs
    # to be called using HTTPS. But we don't care about all that for our local
    # development. So we've to disable security.
    environment:
      # Since Elasticsearch uses Java JVM, so we need to make sure that
      # we've Java installed on our machine!
      # We need to set `ES_JAVA_OPTS` which is just used to configure the
      # Java Virtual Machine (JVM) options for Elasticsearch when it is
      # running inside a Docker container.
      # `-Xmx1g` sets the max heap size that the JVM can use. Here, it means,
      # JVM can use upto 1GB of memory.
      # Heap is the memory space used by Elasticsearch to store data and
      # objects that the JVM needs while running.
      # `Xms1g` sets initial heap size to 1 GB i.e how much memory JVM will
      # allocate when Elasticsearch first starts. Hence, it will reserve 1 GB
      # of memory right away, rather than starting with a smaller amount and
      # growing as needed.
      ES_JAVA_OPTS: -Xmx1g -Xms1g
      # Tell Elasticsearch to lock the JVM heap in memory into RAM. This
      # prevents the operating system from swapping the memory disk, which
      # can be a performance bottleneck because when Elasticsearch is under
      # heavy load, it can handle more data on the memory rather than relying
      # on the disk, improving the performances of searches and data indexing.
      bootstrap.memory_lock: 'true'
      # Configure how Elasticsearch discovers and connects to other nodes in
      # a cluster.
      # Use single node cluster for local development / testing!
      # Elasticsearch is designed to run in a cluster, where multiple nodes
      # (Elasticsearch instances) work together to distribute data and handle
      # queries. By default, Elasticsearch tries to discover other nodes in
      # the network to form a cluster.
      # And when we set it to single-node, we're telling Elasticsearch to
      # run as a single-node cluster, meaning it will not try to discover or
      # communicate with any other nodes. It operates as a standalone instance
      discovery.type: single-node
      # Disable security features
      # Security was disabled by default in version 7. But now, in version 8,
      # we have to manually disable it else it will request it for a valid
      # SSL certificate. We don't need to do all of that in development.
      # Hence, disabling so that it doesn't request for valid SSL certificates.
      # i.e Disable security features in Elasticsearch specifically the
      # authentication and authorization mechanism that are part of X-Pack
      # security.
      # X-Pack is a set of commercial features for Elasticsearch that enhance
      # its capabilities arouond security, monitoring, alerting and more.
      xpack.security.enabled: 'false'
      # Enable the collection of monitoring data, which Elasticsearch can
      # send to a monitoring cluster. This allows us to track metrics like
      # resource usage, performance, indexing rates, etc.
      xpack.monitoring.collection.enabled: 'true'
      # Control whether the Elasticsearch node can enroll in a security-enabled
      # cluster i.e this setting is used when we're working with a security
      # enabled clusters and need to allow nodes to authenticate and securely
      # join the cluster.
      # If in a local or development environment, if security is disabled i.e
      # `xpack.security.enabled: 'fase'`, then this may not be necessary.
      xpack.security.enrollment.enabled: 'true'
      # Enable token based authentication for Elasticsearch which is part of
      # X-Pack Security authentication system. This is typically used in
      # production or secure environments where we want to use token-based
      # authentication for better security and scability. Hence, JWT or other
      # authentication token can be used for authenticating requests to
      # Elasticsearch, rather than requiring traditional username/password
      # authentication.
      xpack.security.authc.token.enabled: 'true'
    # Elastic search runs on port 9200
    ports:
      # This is the port it uses to access the Elasticsearch REST API. But if
      # we're using multi-node cluster, the port that Elasticsearch uses to
      # communicate between those clusters is 9300:9300. But for us during
      # development, its a single-node cluster which is sufficient.
      - 9200:9200
      - 9300:9300
    deploy:
      resources:
        # Specify maximum resource a container can use
        # If the container tries to exceed these limits, Docker will throttle
        # CPU usage and may kill the container if it breaches the memory cap.
        # i.e Limits prevents a container from consuming too much CPU or memory,
        # protecting other containers and the host machine.
        limits:
          memory: 4g # Cannot use more than 4GB RAM i.e memory
          cpus: 2 # Limited to 2 CPU cores
        # Reservations are minimum guaranteed resources for the container
        # i.e Reservations guarantee that the container has enough rsources
        # to run reliably.
        reservations:
          memory: 2g # Guaranteed at least 2GB RAM/memory
          cpus: '1.5' # Guaranteed 1.5 CPU cores
    volumes:
      # Elasticsearch stores data at `/usr/share/elasticsearch/data`
      # But we want to map that to our local elasticsearch-data
      - ./docker-volumes/elasticsearch-data:/usr/share/elasticsearch/data
    # Connect Elasticsearch container to the elastic network. Doing this makes
    # sure that, Elasticsearch container can communicate with other containers
    # that are also connected to this elsatic network.
    networks:
      - elastic
  kibana:
    container_name: kibana_container
    # image: docker.elastic.co/kibana/kibana:7.17.26
    image: docker.elastic.co/kibana/kibana:8.12.2
    restart: always
    environment:
      # We need to set the host. And if we're using the multi node clusters,
      # then we add all the service endpoints to this list. But since we're
      # using only one node, it's going to be just one item in the list which
      # is `http://elasticsearch_container:9200`
      # In order for us to access one of these services, we use the container
      # name. And because they are in the same network, Docker knows how to
      # handle it. If they're running in different networks then that is a
      # different case. But they're running in the same network, so Docker
      # knows how to handle it. Thus, the service can be accessed with
      # unique url.
      # So with this url, Kibana will get access to the Elasticsearch service.
      - ELASTICSEARCH_HOST=['http://elasticsearch_container:9200']
    # Port for Kibana is 5601
    ports:
      - 5601:5601
    networks:
      - elastic
    volumes:
      # There are several methods for configuring Kibana on Docker. But
      # conventional approach is, we provide a `kibana.yml` file
      # Provide kibana.yml file to replace the `kibana.yml` located in the
      # `/usr/share/kibana/config/kibana.yml`
      # So kibana.yml file we're providing will replace the kibana inside the
      # config folder. If we dont specifiy kibana.yml file, its going to use
      # the default kibana.yml file located in the config but if we provide
      # one, it will replace/overrides.
      # The reason we're doing this is so that we can specify our Elasticsearch
      # service path i.e `[http://elasticsearch_container:9200]`
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    # We don't want Kibana to start until Elasticsearch is running because
    # Kibana depends on Elasticsearch.
    depends_on:
      - elasticsearch

#Tell Docker Compose to create a network called elastic so that any
# service (container) that needs to communicate with other services
# in the same network will be connected to this elastic network.
networks:
  elastic:
    name: elastic
